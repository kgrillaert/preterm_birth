{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     98
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb63d2786c44cacb211d472861af617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/895441 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_30352193_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                JOIN\n",
    "                    (\n",
    "                        select\n",
    "                            cast(cr.id as string) as id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                        WHERE\n",
    "                            concept_id IN (\n",
    "                                1586134,43528895,40192389\n",
    "                            ) \n",
    "                            AND domain_id = 'SURVEY'\n",
    "                    ) a \n",
    "                        ON (\n",
    "                            c.path like CONCAT('%',\n",
    "                        a.id,\n",
    "                        '.%')) \n",
    "                    WHERE\n",
    "                        domain_id = 'SURVEY' \n",
    "                        AND type = 'PPI' \n",
    "                        AND subtype = 'QUESTION'\n",
    "                    )\n",
    "            )  \n",
    "            AND (\n",
    "                answer.PERSON_ID IN (\n",
    "                    SELECT\n",
    "                        distinct person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                    WHERE\n",
    "                        cb_search_person.person_id IN (\n",
    "                            SELECT\n",
    "                                criteria.person_id \n",
    "                            FROM\n",
    "                                (SELECT\n",
    "                                    DISTINCT person_id,\n",
    "                                    entry_date,\n",
    "                                    concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                WHERE\n",
    "                                    (\n",
    "                                        concept_id IN (\n",
    "                                            SELECT\n",
    "                                                DISTINCT c.concept_id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                            JOIN\n",
    "                                                (\n",
    "                                                    select\n",
    "                                                        cast(cr.id as string) as id \n",
    "                                                    FROM\n",
    "                                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                    WHERE\n",
    "                                                        concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                        AND full_text LIKE '%_rank1]%'\n",
    "                                                ) a \n",
    "                                                    ON (\n",
    "                                                        c.path LIKE CONCAT('%.',\n",
    "                                                    a.id,\n",
    "                                                    '.%') \n",
    "                                                    OR c.path LIKE CONCAT('%.',\n",
    "                                                    a.id) \n",
    "                                                    OR c.path LIKE CONCAT(a.id,\n",
    "                                                    '.%') \n",
    "                                                    OR c.path = a.id) \n",
    "                                                WHERE\n",
    "                                                    is_standard = 1 \n",
    "                                                    AND is_selectable = 1\n",
    "                                                ) \n",
    "                                                AND is_standard = 1 \n",
    "                                        )\n",
    "                                    ) criteria \n",
    "                                ) ))\"\"\"\n",
    "\n",
    "dataset_30352193_survey_df = pandas.read_gbq(\n",
    "    dataset_30352193_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "#dataset_30352193_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4,
     5,
     128,
     129,
     131,
     135
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efeb3a4204245bb9c2155b390d9a98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/44593 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_30352193_condition_sql = \"\"\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_occurrence.condition_type_concept_id,\n",
    "        c_type.concept_name as condition_type_concept_name,\n",
    "        c_occurrence.stop_reason,\n",
    "        c_occurrence.visit_occurrence_id,\n",
    "        visit.concept_name as visit_occurrence_concept_name,\n",
    "        c_occurrence.condition_source_value,\n",
    "        c_occurrence.condition_source_concept_id,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code,\n",
    "        c_source_concept.vocabulary_id as source_vocabulary,\n",
    "        c_occurrence.condition_status_source_value,\n",
    "        c_occurrence.condition_status_concept_id,\n",
    "        c_status.concept_name as condition_status_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN  (\n",
    "                    SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (\n",
    "                            select\n",
    "                                cast(cr.id as string) as id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                            WHERE\n",
    "                                concept_id IN (\n",
    "                                    36712702, 4014295, 44784550, 45757175, 45757176\n",
    "                                ) \n",
    "                                AND full_text LIKE '%_rank1]%'\n",
    "                        ) a \n",
    "                            ON (\n",
    "                                c.path LIKE CONCAT('%.',\n",
    "                            a.id,\n",
    "                            '.%') \n",
    "                            OR c.path LIKE CONCAT('%.',\n",
    "                            a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id,\n",
    "                            '.%') \n",
    "                            OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1\n",
    "                        )\n",
    "                )  \n",
    "                AND (\n",
    "                    c_occurrence.PERSON_ID IN (\n",
    "                        SELECT\n",
    "                            distinct person_id  \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                        WHERE\n",
    "                            cb_search_person.person_id IN (\n",
    "                                SELECT\n",
    "                                    criteria.person_id \n",
    "                                FROM\n",
    "                                    (SELECT\n",
    "                                        DISTINCT person_id,\n",
    "                                        entry_date,\n",
    "                                        concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                    WHERE\n",
    "                                        (\n",
    "                                            concept_id IN (\n",
    "                                                SELECT\n",
    "                                                    DISTINCT c.concept_id \n",
    "                                                FROM\n",
    "                                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                                JOIN\n",
    "                                                    (\n",
    "                                                        select\n",
    "                                                            cast(cr.id as string) as id \n",
    "                                                        FROM\n",
    "                                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                        WHERE\n",
    "                                                            concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                            AND full_text LIKE '%_rank1]%'\n",
    "                                                    ) a \n",
    "                                                        ON (\n",
    "                                                            c.path LIKE CONCAT('%.',\n",
    "                                                        a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path LIKE CONCAT('%.',\n",
    "                                                        a.id) \n",
    "                                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path = a.id) \n",
    "                                                    WHERE\n",
    "                                                        is_standard = 1 \n",
    "                                                        AND is_selectable = 1\n",
    "                                                    ) \n",
    "                                                    AND is_standard = 1 \n",
    "                                            )\n",
    "                                        ) criteria \n",
    "                                    ) ))\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "dataset_30352193_condition_df = pandas.read_gbq(\n",
    "    dataset_30352193_condition_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "#dataset_30352193_condition_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     4,
     5,
     16,
     18,
     22,
     24,
     27,
     88
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1e9d8c568d4b8d90ae18067715d0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/17524 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_30352193_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) )  \n",
    "                    AND (person.PERSON_ID IN (SELECT\n",
    "                        DISTINCT person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1))\"\"\"\n",
    "\n",
    "dataset_30352193_person_df = pandas.read_gbq(\n",
    "    dataset_30352193_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "#dataset_30352193_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     79
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001ecc7bb4140af8c2942fb6baebae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/17517 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_30352193_zip_code_socioeconomic_sql = \"\"\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".zip3_ses_map` zip_code \n",
    "    JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string,\n",
    "        0,\n",
    "        STRPOS(observation.value_as_string,\n",
    "        '*') - 1) AS INT64) = zip_code.zip3  \n",
    "    WHERE\n",
    "        observation.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) ) \n",
    "                    AND observation_source_concept_id = 1585250 \n",
    "                    AND observation.value_as_string NOT LIKE 'Res%'\"\"\"\n",
    "\n",
    "dataset_30352193_zip_code_socioeconomic_df = pandas.read_gbq(\n",
    "    dataset_30352193_zip_code_socioeconomic_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "#dataset_30352193_zip_code_socioeconomic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages needed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename dataframes to be easier to work with\n",
    "\n",
    "# df1\n",
    "\n",
    "# the columns question_concept_id, answer_concept_id, survey_version_concept_id\n",
    "# throw problems and aren't helpful, so I'm going to drop them here\n",
    "\n",
    "# every entry in survey_version_name is None, so I'm dropping that column as well\n",
    "\n",
    "# the entries in survey, are all one of 'The Basics', 'Healthcare Access & Utilization',\n",
    "# or 'Social Determinants of Health'. I'm dropping this column too\n",
    "\n",
    "# actually, the remaining columns are asking if the person is deaf (question, answer are separate columns),\n",
    "# and the datetime of the survey. I don't think we are going to use any of these,\n",
    "# so I'm actually just not going to use df1\n",
    "\n",
    "#df1 = dataset_30352193_survey_df.drop(columns=[\"question_concept_id\", \"answer_concept_id\", \"survey_version_concept_id\", \"survey_version_name\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df2 \n",
    "\n",
    "# the columns 'condition_concept_id', 'condition_type_concept_id', 'visit_occurrence_id', \n",
    "# 'condition_source_concept_id', 'condition_status_concept_id' throw problems\n",
    "# and aren't helpful, so I'm going to drop them at the beginning\n",
    "\n",
    "# 'standard_concept_code' is just a code for 'standard_concept_name', so I'm dropping it\n",
    "\n",
    "# 'standard_vocabulary' is always 'SNOMED', so I'm dropping it\n",
    "# 'stop_reason' is always 'None', so I'm dropping it\n",
    "\n",
    "# 'condition_source_value' and 'source_concept_code' have the same codes, same value counts,\n",
    "# and match in the first few rows, so I'm dropping 'source_concept_code'\n",
    "\n",
    "# 'condition_source_value' and 'source_concept_name' are almost the same ('source_concept_name'\n",
    "# combines two values into the same name twice), but not identical\n",
    "\n",
    "# 'condition_source_value' and 'condition_status_source_value' are almost the same,\n",
    "# but some things in 'condition_source_value' yield 'no matching concept' in 'condition_status_source_value'\n",
    "\n",
    "# 'condition_status_concept_name' are the names for 'condition_status_source_value'\n",
    "\n",
    "# for now, I'm keeping 'source_concept_name' and 'condition_status_concept_name',\n",
    "# and dropping 'condition_source_value' and 'condition_status_source_value'\n",
    "\n",
    "df2_drop_columns = ['condition_concept_id', 'condition_type_concept_id', 'visit_occurrence_id',]\n",
    "df2_drop_columns.extend(['condition_source_concept_id', 'condition_status_concept_id', 'standard_concept_code'])\n",
    "df2_drop_columns.extend(['standard_vocabulary', 'stop_reason', 'source_concept_code'])\n",
    "df2_drop_columns.extend(['condition_source_value', 'condition_status_source_value'])\n",
    "\n",
    "df2 = dataset_30352193_condition_df.drop(columns=df2_drop_columns)\n",
    "\n",
    "\n",
    "\n",
    "# df3\n",
    "\n",
    "# Dropping 'gender_concept_id', keeping 'gender'\n",
    "# Dropping 'race_concept_id', keeping 'race'\n",
    "# Dropping 'ethnicity_concept_id', keeping 'ethnicity'\n",
    "# Dropping 'sex_at_birth_concept_id', keeping 'sex_at_birth'\n",
    "\n",
    "df3_drop_columns = ['gender_concept_id', 'race_concept_id', 'ethnicity_concept_id', 'sex_at_birth_concept_id']\n",
    "\n",
    "df3 = dataset_30352193_person_df.drop(columns=df3_drop_columns)\n",
    "\n",
    "\n",
    "\n",
    "# df4\n",
    "\n",
    "# note this wikipedia list of zip_code prefixes (i.e. first 3 digits):\n",
    "# https://en.wikipedia.org/wiki/List_of_ZIP_Code_prefixes\n",
    "\n",
    "# Not currently dropping any values from df4\n",
    "\n",
    "df4 = dataset_30352193_zip_code_socioeconomic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of values of person_id and multiplicities in each data frame\n",
    "\n",
    "## start by creating sets of unique ids\n",
    "\n",
    "#unique_ids1 = list(df1.person_id.unique())\n",
    "\n",
    "unique_ids2 = list(df2.person_id.unique())\n",
    "unique_ids3 = list(df3.person_id.unique())\n",
    "unique_ids4 = list(df4.person_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17517\n"
     ]
    }
   ],
   "source": [
    "## create a set of values of person_id that occur in each data frame\n",
    "## we then sort common_ids in ascending order\n",
    "\n",
    "## since we only have four data frames, easy to construct full hierarchy, if we want\n",
    "\n",
    "common_ids = []\n",
    "\n",
    "for pid in unique_ids2:\n",
    "    if (pid in unique_ids3) and (pid in unique_ids4):\n",
    "        common_ids.append(pid)\n",
    "\n",
    "common_ids.sort()\n",
    "        \n",
    "## print(len(common_ids))\n",
    "## As of 27 Oct 2023, len(common_ids) = 17517, both with and without df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## restrict df1, df2, df3, df4 to rows with personal_id values in common_ids\n",
    "\n",
    "## I think it will be helpful to sort the restricted data frames\n",
    "## Also, we sort by person_id\n",
    "\n",
    "# restricted1 = df1[df1[\"person_id\"].isin(common_ids)].sort_values(by=[\"person_id\"]).copy()\n",
    "\n",
    "restricted2 = df2[df2[\"person_id\"].isin(common_ids)].sort_values(by=[\"person_id\"]).copy()\n",
    "restricted3 = df3[df3[\"person_id\"].isin(common_ids)].sort_values(by=[\"person_id\"]).copy()\n",
    "restricted4 = df4[df4[\"person_id\"].isin(common_ids)].sort_values(by=[\"person_id\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## since only df1 and df2 have rows with repeated person_id values,\n",
    "## we create dictionaries for df1 and df2 to track how many times\n",
    "## each element of common_ids occurs as a person_id value\n",
    "\n",
    "#dict1 = {}\n",
    "\n",
    "#for pid in restricted1.person_id:\n",
    "#    if pid in dict1.keys():\n",
    "#        dict1[pid] += 1\n",
    "#    else:\n",
    "#        dict1[pid] = 1\n",
    "\n",
    "dict2 = {}\n",
    "\n",
    "for pid in restricted2.person_id:\n",
    "    if pid in dict2.keys():\n",
    "        dict2[pid] += 1\n",
    "    else:\n",
    "        dict2[pid] = 1\n",
    "        \n",
    "#print(dict1)\n",
    "#print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df3 has 6 columns, including the personal id column,      so df3 will add 5 columns\n",
      "df4 has 11 columns, including the personal id column,      so df4 will add 10 columns\n",
      " \n",
      "df2 has 9 columns, including the personal id column\n",
      "Since the highest multiplicity in dict2 is 49, df2 will add\n",
      "49(9-1) = 392 columns\n",
      " \n",
      "Our new data frame will have 408 columns\n"
     ]
    }
   ],
   "source": [
    "## assuming that we want to keep data from each row in the restricted frame,\n",
    "## we now find the highest multiplicity, so we now determine how many columns we will need\n",
    "\n",
    "## currently, I am assuming that df1, df2, df3, df4 all distinct columns in our actual data, apart from person_id\n",
    "## if this isn't true, it will be easy to fix in the future\n",
    "\n",
    "## note that we have only restricted the rows, columns are still the same, so df1.columns = restricted1.columns\n",
    "\n",
    "#dict1_mult = max(dict1.values())\n",
    "dict2_mult = max(dict2.values())\n",
    "\n",
    "#print(dict1_mult)\n",
    "\n",
    "print(\"df3 has \" + str(len(df3.columns)) + \" columns, including the personal id column,\\\n",
    "      so df3 will add \" + str(len(df3.columns)-1) + \" columns\")\n",
    "print(\"df4 has \" + str(len(df4.columns)) + \" columns, including the personal id column,\\\n",
    "      so df4 will add \" + str(len(df4.columns)-1) + \" columns\")\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "#print(\"df1 has \" + str(len(df1.columns)) + \" columns, including the personal id column\")\n",
    "#print(\"Since the highest multiplicity in dict1 is \" + str(dict1_mult) + \", df1 will add\")\n",
    "#print(str(dict1_mult) + \"(\" + str( len(df1.columns) ) + \"-1) = \" + str( dict1_mult*(len(df1.columns)-1) ) + \" columns\")\n",
    "\n",
    "#print(\" \")\n",
    "\n",
    "print(\"df2 has \" + str(len(df2.columns)) + \" columns, including the personal id column\")\n",
    "print(\"Since the highest multiplicity in dict2 is \" + str(dict2_mult) + \", df2 will add\")\n",
    "print(str(dict2_mult) + \"(\" + str( len(df2.columns) ) + \"-1) = \" + str( dict2_mult*(len(df2.columns)-1) ) + \" columns\" )\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "#total_cols = len(df3.columns) + len(df4.columns) - 1 + dict1_mult*(len(df1.columns)-1) + dict2_mult*(len(df2.columns)-1)\n",
    "total_cols = len(df3.columns) + len(df4.columns) - 1 + dict2_mult*(len(df2.columns)-1)\n",
    "\n",
    "print(\"Our new data frame will have \" + str(total_cols) + \" columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_df3</th>\n",
       "      <th>date_of_birth_df3</th>\n",
       "      <th>race_df3</th>\n",
       "      <th>ethnicity_df3</th>\n",
       "      <th>sex_at_birth_df3</th>\n",
       "      <th>observation_datetime_df4</th>\n",
       "      <th>zip_code_df4</th>\n",
       "      <th>assisted_income_df4</th>\n",
       "      <th>high_school_education_df4</th>\n",
       "      <th>...</th>\n",
       "      <th>source_vocabulary_df2_48</th>\n",
       "      <th>condition_status_concept_name_df2_48</th>\n",
       "      <th>standard_concept_name_df2_49</th>\n",
       "      <th>condition_start_datetime_df2_49</th>\n",
       "      <th>condition_end_datetime_df2_49</th>\n",
       "      <th>condition_type_concept_name_df2_49</th>\n",
       "      <th>visit_occurrence_concept_name_df2_49</th>\n",
       "      <th>source_concept_name_df2_49</th>\n",
       "      <th>source_vocabulary_df2_49</th>\n",
       "      <th>condition_status_concept_name_df2_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 408 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [person_id, gender_df3, date_of_birth_df3, race_df3, ethnicity_df3, sex_at_birth_df3, observation_datetime_df4, zip_code_df4, assisted_income_df4, high_school_education_df4, median_income_df4, no_health_insurance_df4, poverty_df4, vacant_housing_df4, deprivation_index_df4, american_community_survey_year_df4, standard_concept_name_df2_1, condition_start_datetime_df2_1, condition_end_datetime_df2_1, condition_type_concept_name_df2_1, visit_occurrence_concept_name_df2_1, source_concept_name_df2_1, source_vocabulary_df2_1, condition_status_concept_name_df2_1, standard_concept_name_df2_2, condition_start_datetime_df2_2, condition_end_datetime_df2_2, condition_type_concept_name_df2_2, visit_occurrence_concept_name_df2_2, source_concept_name_df2_2, source_vocabulary_df2_2, condition_status_concept_name_df2_2, standard_concept_name_df2_3, condition_start_datetime_df2_3, condition_end_datetime_df2_3, condition_type_concept_name_df2_3, visit_occurrence_concept_name_df2_3, source_concept_name_df2_3, source_vocabulary_df2_3, condition_status_concept_name_df2_3, standard_concept_name_df2_4, condition_start_datetime_df2_4, condition_end_datetime_df2_4, condition_type_concept_name_df2_4, visit_occurrence_concept_name_df2_4, source_concept_name_df2_4, source_vocabulary_df2_4, condition_status_concept_name_df2_4, standard_concept_name_df2_5, condition_start_datetime_df2_5, condition_end_datetime_df2_5, condition_type_concept_name_df2_5, visit_occurrence_concept_name_df2_5, source_concept_name_df2_5, source_vocabulary_df2_5, condition_status_concept_name_df2_5, standard_concept_name_df2_6, condition_start_datetime_df2_6, condition_end_datetime_df2_6, condition_type_concept_name_df2_6, visit_occurrence_concept_name_df2_6, source_concept_name_df2_6, source_vocabulary_df2_6, condition_status_concept_name_df2_6, standard_concept_name_df2_7, condition_start_datetime_df2_7, condition_end_datetime_df2_7, condition_type_concept_name_df2_7, visit_occurrence_concept_name_df2_7, source_concept_name_df2_7, source_vocabulary_df2_7, condition_status_concept_name_df2_7, standard_concept_name_df2_8, condition_start_datetime_df2_8, condition_end_datetime_df2_8, condition_type_concept_name_df2_8, visit_occurrence_concept_name_df2_8, source_concept_name_df2_8, source_vocabulary_df2_8, condition_status_concept_name_df2_8, standard_concept_name_df2_9, condition_start_datetime_df2_9, condition_end_datetime_df2_9, condition_type_concept_name_df2_9, visit_occurrence_concept_name_df2_9, source_concept_name_df2_9, source_vocabulary_df2_9, condition_status_concept_name_df2_9, standard_concept_name_df2_10, condition_start_datetime_df2_10, condition_end_datetime_df2_10, condition_type_concept_name_df2_10, visit_occurrence_concept_name_df2_10, source_concept_name_df2_10, source_vocabulary_df2_10, condition_status_concept_name_df2_10, standard_concept_name_df2_11, condition_start_datetime_df2_11, condition_end_datetime_df2_11, condition_type_concept_name_df2_11, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 408 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we now create a new data frame with the appropriate number of columns\n",
    "\n",
    "col_list = []\n",
    "\n",
    "for col in df3.columns:\n",
    "    if col == \"person_id\":\n",
    "        col_list.append(col)\n",
    "    else:\n",
    "        col_list.append(col+\"_df3\")\n",
    "\n",
    "for col in df4.columns:\n",
    "    if col != \"person_id\":\n",
    "        col_list.append(col+\"_df4\")\n",
    "\n",
    "#for index in range(1,dict1_mult+1):\n",
    "#    for col in df1.columns:\n",
    "#        if col != \"person_id\":\n",
    "#            col_list.append(col+\"_df1_\"+str(index))\n",
    "\n",
    "for index in range(1,dict2_mult+1):\n",
    "    for col in df2.columns:\n",
    "        if col != \"person_id\":\n",
    "            col_list.append(col+\"_df2_\"+str(index))\n",
    "\n",
    "combined_df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_df3</th>\n",
       "      <th>date_of_birth_df3</th>\n",
       "      <th>race_df3</th>\n",
       "      <th>ethnicity_df3</th>\n",
       "      <th>sex_at_birth_df3</th>\n",
       "      <th>observation_datetime_df4</th>\n",
       "      <th>zip_code_df4</th>\n",
       "      <th>assisted_income_df4</th>\n",
       "      <th>high_school_education_df4</th>\n",
       "      <th>median_income_df4</th>\n",
       "      <th>...</th>\n",
       "      <th>source_vocabulary_df2_48</th>\n",
       "      <th>condition_status_concept_name_df2_48</th>\n",
       "      <th>standard_concept_name_df2_49</th>\n",
       "      <th>condition_start_datetime_df2_49</th>\n",
       "      <th>condition_end_datetime_df2_49</th>\n",
       "      <th>condition_type_concept_name_df2_49</th>\n",
       "      <th>visit_occurrence_concept_name_df2_49</th>\n",
       "      <th>source_concept_name_df2_49</th>\n",
       "      <th>source_vocabulary_df2_49</th>\n",
       "      <th>condition_status_concept_name_df2_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000104</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000109</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000131</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000291</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000724</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001000</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001034</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001161</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001207</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gender_df3 date_of_birth_df3 race_df3 ethnicity_df3  \\\n",
       "person_id                                                       \n",
       "1000104         temp              temp     temp          temp   \n",
       "1000109         temp              temp     temp          temp   \n",
       "1000131         temp              temp     temp          temp   \n",
       "1000195         temp              temp     temp          temp   \n",
       "1000291         temp              temp     temp          temp   \n",
       "1000724         temp              temp     temp          temp   \n",
       "1001000         temp              temp     temp          temp   \n",
       "1001034         temp              temp     temp          temp   \n",
       "1001161         temp              temp     temp          temp   \n",
       "1001207         temp              temp     temp          temp   \n",
       "\n",
       "          sex_at_birth_df3 observation_datetime_df4 zip_code_df4  \\\n",
       "person_id                                                          \n",
       "1000104               temp                     temp         temp   \n",
       "1000109               temp                     temp         temp   \n",
       "1000131               temp                     temp         temp   \n",
       "1000195               temp                     temp         temp   \n",
       "1000291               temp                     temp         temp   \n",
       "1000724               temp                     temp         temp   \n",
       "1001000               temp                     temp         temp   \n",
       "1001034               temp                     temp         temp   \n",
       "1001161               temp                     temp         temp   \n",
       "1001207               temp                     temp         temp   \n",
       "\n",
       "          assisted_income_df4 high_school_education_df4 median_income_df4  \\\n",
       "person_id                                                                   \n",
       "1000104                  temp                      temp              temp   \n",
       "1000109                  temp                      temp              temp   \n",
       "1000131                  temp                      temp              temp   \n",
       "1000195                  temp                      temp              temp   \n",
       "1000291                  temp                      temp              temp   \n",
       "1000724                  temp                      temp              temp   \n",
       "1001000                  temp                      temp              temp   \n",
       "1001034                  temp                      temp              temp   \n",
       "1001161                  temp                      temp              temp   \n",
       "1001207                  temp                      temp              temp   \n",
       "\n",
       "           ... source_vocabulary_df2_48 condition_status_concept_name_df2_48  \\\n",
       "person_id  ...                                                                 \n",
       "1000104    ...                     temp                                 temp   \n",
       "1000109    ...                     temp                                 temp   \n",
       "1000131    ...                     temp                                 temp   \n",
       "1000195    ...                     temp                                 temp   \n",
       "1000291    ...                     temp                                 temp   \n",
       "1000724    ...                     temp                                 temp   \n",
       "1001000    ...                     temp                                 temp   \n",
       "1001034    ...                     temp                                 temp   \n",
       "1001161    ...                     temp                                 temp   \n",
       "1001207    ...                     temp                                 temp   \n",
       "\n",
       "          standard_concept_name_df2_49 condition_start_datetime_df2_49  \\\n",
       "person_id                                                                \n",
       "1000104                           temp                            temp   \n",
       "1000109                           temp                            temp   \n",
       "1000131                           temp                            temp   \n",
       "1000195                           temp                            temp   \n",
       "1000291                           temp                            temp   \n",
       "1000724                           temp                            temp   \n",
       "1001000                           temp                            temp   \n",
       "1001034                           temp                            temp   \n",
       "1001161                           temp                            temp   \n",
       "1001207                           temp                            temp   \n",
       "\n",
       "          condition_end_datetime_df2_49 condition_type_concept_name_df2_49  \\\n",
       "person_id                                                                    \n",
       "1000104                            temp                               temp   \n",
       "1000109                            temp                               temp   \n",
       "1000131                            temp                               temp   \n",
       "1000195                            temp                               temp   \n",
       "1000291                            temp                               temp   \n",
       "1000724                            temp                               temp   \n",
       "1001000                            temp                               temp   \n",
       "1001034                            temp                               temp   \n",
       "1001161                            temp                               temp   \n",
       "1001207                            temp                               temp   \n",
       "\n",
       "          visit_occurrence_concept_name_df2_49 source_concept_name_df2_49  \\\n",
       "person_id                                                                   \n",
       "1000104                                   temp                       temp   \n",
       "1000109                                   temp                       temp   \n",
       "1000131                                   temp                       temp   \n",
       "1000195                                   temp                       temp   \n",
       "1000291                                   temp                       temp   \n",
       "1000724                                   temp                       temp   \n",
       "1001000                                   temp                       temp   \n",
       "1001034                                   temp                       temp   \n",
       "1001161                                   temp                       temp   \n",
       "1001207                                   temp                       temp   \n",
       "\n",
       "          source_vocabulary_df2_49 condition_status_concept_name_df2_49  \n",
       "person_id                                                                \n",
       "1000104                       temp                                 temp  \n",
       "1000109                       temp                                 temp  \n",
       "1000131                       temp                                 temp  \n",
       "1000195                       temp                                 temp  \n",
       "1000291                       temp                                 temp  \n",
       "1000724                       temp                                 temp  \n",
       "1001000                       temp                                 temp  \n",
       "1001034                       temp                                 temp  \n",
       "1001161                       temp                                 temp  \n",
       "1001207                       temp                                 temp  \n",
       "\n",
       "[10 rows x 407 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we will now populate our new data frame, combined_df, with rows\n",
    "## for each value pid of person_id in common_ids, we will create a row with person_id=pid and all other columns=\"temp\"\n",
    "## we also set the index of combined_df to person_id\n",
    "## I had added a step here to sort by person_id, but instead I sorted common_ids after it was created\n",
    "\n",
    "## When using all columns and including df1, I observed the following:\n",
    "## This takes awhile, I'm going to sample it a subset of about 1000 of the common_ids\n",
    "## Takes about 2 mins, 30 secs to do 1000.\n",
    "## I imagine the slow part is concatenating every step. I'll think about making this faster.\n",
    "\n",
    "## Without df1 and all of the columns, I observed:\n",
    "## While still using only the first 1000 common_ids, it now takes about 25 sec.\n",
    "\n",
    "## Without df1 and all of the columns, I observed:\n",
    "## While using common_ids, I let it run for 16 minutes and it didn't finish yet.\n",
    "## It's late though, so I'm going to continue using common_ids_sub_1 and we can address this later\n",
    "\n",
    "common_ids_sub_1 = common_ids[0:1000]\n",
    "\n",
    "\n",
    "temp_dict = {}\n",
    "for col in col_list:\n",
    "    if col != \"person_id\":\n",
    "        temp_dict[col] = [\"temp\"]\n",
    "\n",
    "for pid in common_ids_sub_1:\n",
    "    pid_dict = {\"person_id\":pid}\n",
    "    pid_dict.update(temp_dict)\n",
    "    pid_df = pd.DataFrame(pid_dict)\n",
    "    combined_df = pd.concat([combined_df, pid_df])\n",
    "\n",
    "#combined_df.sort_values(by=[\"person_id\"])\n",
    "combined_df.set_index(\"person_id\", inplace=True)\n",
    "\n",
    "    \n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_df3</th>\n",
       "      <th>date_of_birth_df3</th>\n",
       "      <th>race_df3</th>\n",
       "      <th>ethnicity_df3</th>\n",
       "      <th>sex_at_birth_df3</th>\n",
       "      <th>observation_datetime_df4</th>\n",
       "      <th>zip_code_df4</th>\n",
       "      <th>assisted_income_df4</th>\n",
       "      <th>high_school_education_df4</th>\n",
       "      <th>median_income_df4</th>\n",
       "      <th>...</th>\n",
       "      <th>source_vocabulary_df2_48</th>\n",
       "      <th>condition_status_concept_name_df2_48</th>\n",
       "      <th>standard_concept_name_df2_49</th>\n",
       "      <th>condition_start_datetime_df2_49</th>\n",
       "      <th>condition_end_datetime_df2_49</th>\n",
       "      <th>condition_type_concept_name_df2_49</th>\n",
       "      <th>visit_occurrence_concept_name_df2_49</th>\n",
       "      <th>source_concept_name_df2_49</th>\n",
       "      <th>source_vocabulary_df2_49</th>\n",
       "      <th>condition_status_concept_name_df2_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000104</th>\n",
       "      <td>Female</td>\n",
       "      <td>1965-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000109</th>\n",
       "      <td>Female</td>\n",
       "      <td>1967-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000131</th>\n",
       "      <td>Not man only, not woman only, prefer not to an...</td>\n",
       "      <td>2002-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000291</th>\n",
       "      <td>Female</td>\n",
       "      <td>1962-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000724</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001000</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001034</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None of these</td>\n",
       "      <td>What Race Ethnicity: Race Ethnicity None Of These</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001161</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001207</th>\n",
       "      <td>Female</td>\n",
       "      <td>1985-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gender_df3  \\\n",
       "person_id                                                      \n",
       "1000104                                               Female   \n",
       "1000109                                               Female   \n",
       "1000131    Not man only, not woman only, prefer not to an...   \n",
       "1000195                                               Female   \n",
       "1000291                                               Female   \n",
       "1000724                                               Female   \n",
       "1001000                                               Female   \n",
       "1001034                                               Female   \n",
       "1001161                                               Female   \n",
       "1001207                                               Female   \n",
       "\n",
       "                   date_of_birth_df3                   race_df3  \\\n",
       "person_id                                                         \n",
       "1000104    1965-06-15 00:00:00+00:00             None Indicated   \n",
       "1000109    1967-06-15 00:00:00+00:00             None Indicated   \n",
       "1000131    2002-06-15 00:00:00+00:00                      White   \n",
       "1000195    1982-06-15 00:00:00+00:00  Black or African American   \n",
       "1000291    1962-06-15 00:00:00+00:00             None Indicated   \n",
       "1000724    1999-06-15 00:00:00+00:00                      White   \n",
       "1001000    1999-06-15 00:00:00+00:00  Black or African American   \n",
       "1001034    1989-06-15 00:00:00+00:00              None of these   \n",
       "1001161    1989-06-15 00:00:00+00:00             None Indicated   \n",
       "1001207    1985-06-15 00:00:00+00:00             None Indicated   \n",
       "\n",
       "                                               ethnicity_df3 sex_at_birth_df3  \\\n",
       "person_id                                                                       \n",
       "1000104                                   Hispanic or Latino           Female   \n",
       "1000109                                   Hispanic or Latino           Female   \n",
       "1000131                               Not Hispanic or Latino           Female   \n",
       "1000195                               Not Hispanic or Latino           Female   \n",
       "1000291                                   Hispanic or Latino           Female   \n",
       "1000724                               Not Hispanic or Latino           Female   \n",
       "1001000                                   Hispanic or Latino           Female   \n",
       "1001034    What Race Ethnicity: Race Ethnicity None Of These           Female   \n",
       "1001161                                   Hispanic or Latino           Female   \n",
       "1001207                                   Hispanic or Latino           Female   \n",
       "\n",
       "          observation_datetime_df4 zip_code_df4 assisted_income_df4  \\\n",
       "person_id                                                             \n",
       "1000104                       temp         temp                temp   \n",
       "1000109                       temp         temp                temp   \n",
       "1000131                       temp         temp                temp   \n",
       "1000195                       temp         temp                temp   \n",
       "1000291                       temp         temp                temp   \n",
       "1000724                       temp         temp                temp   \n",
       "1001000                       temp         temp                temp   \n",
       "1001034                       temp         temp                temp   \n",
       "1001161                       temp         temp                temp   \n",
       "1001207                       temp         temp                temp   \n",
       "\n",
       "          high_school_education_df4 median_income_df4  ...  \\\n",
       "person_id                                              ...   \n",
       "1000104                        temp              temp  ...   \n",
       "1000109                        temp              temp  ...   \n",
       "1000131                        temp              temp  ...   \n",
       "1000195                        temp              temp  ...   \n",
       "1000291                        temp              temp  ...   \n",
       "1000724                        temp              temp  ...   \n",
       "1001000                        temp              temp  ...   \n",
       "1001034                        temp              temp  ...   \n",
       "1001161                        temp              temp  ...   \n",
       "1001207                        temp              temp  ...   \n",
       "\n",
       "          source_vocabulary_df2_48 condition_status_concept_name_df2_48  \\\n",
       "person_id                                                                 \n",
       "1000104                       temp                                 temp   \n",
       "1000109                       temp                                 temp   \n",
       "1000131                       temp                                 temp   \n",
       "1000195                       temp                                 temp   \n",
       "1000291                       temp                                 temp   \n",
       "1000724                       temp                                 temp   \n",
       "1001000                       temp                                 temp   \n",
       "1001034                       temp                                 temp   \n",
       "1001161                       temp                                 temp   \n",
       "1001207                       temp                                 temp   \n",
       "\n",
       "          standard_concept_name_df2_49 condition_start_datetime_df2_49  \\\n",
       "person_id                                                                \n",
       "1000104                           temp                            temp   \n",
       "1000109                           temp                            temp   \n",
       "1000131                           temp                            temp   \n",
       "1000195                           temp                            temp   \n",
       "1000291                           temp                            temp   \n",
       "1000724                           temp                            temp   \n",
       "1001000                           temp                            temp   \n",
       "1001034                           temp                            temp   \n",
       "1001161                           temp                            temp   \n",
       "1001207                           temp                            temp   \n",
       "\n",
       "          condition_end_datetime_df2_49 condition_type_concept_name_df2_49  \\\n",
       "person_id                                                                    \n",
       "1000104                            temp                               temp   \n",
       "1000109                            temp                               temp   \n",
       "1000131                            temp                               temp   \n",
       "1000195                            temp                               temp   \n",
       "1000291                            temp                               temp   \n",
       "1000724                            temp                               temp   \n",
       "1001000                            temp                               temp   \n",
       "1001034                            temp                               temp   \n",
       "1001161                            temp                               temp   \n",
       "1001207                            temp                               temp   \n",
       "\n",
       "          visit_occurrence_concept_name_df2_49 source_concept_name_df2_49  \\\n",
       "person_id                                                                   \n",
       "1000104                                   temp                       temp   \n",
       "1000109                                   temp                       temp   \n",
       "1000131                                   temp                       temp   \n",
       "1000195                                   temp                       temp   \n",
       "1000291                                   temp                       temp   \n",
       "1000724                                   temp                       temp   \n",
       "1001000                                   temp                       temp   \n",
       "1001034                                   temp                       temp   \n",
       "1001161                                   temp                       temp   \n",
       "1001207                                   temp                       temp   \n",
       "\n",
       "          source_vocabulary_df2_49 condition_status_concept_name_df2_49  \n",
       "person_id                                                                \n",
       "1000104                       temp                                 temp  \n",
       "1000109                       temp                                 temp  \n",
       "1000131                       temp                                 temp  \n",
       "1000195                       temp                                 temp  \n",
       "1000291                       temp                                 temp  \n",
       "1000724                       temp                                 temp  \n",
       "1001000                       temp                                 temp  \n",
       "1001034                       temp                                 temp  \n",
       "1001161                       temp                                 temp  \n",
       "1001207                       temp                                 temp  \n",
       "\n",
       "[10 rows x 407 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## next want to fill in combined_df with actual values from restricted1, restricted2, restricted3, restricted4\n",
    "\n",
    "## for restricted3 and restricted4, there are unique rows for each value of person_id, so we start with those\n",
    "\n",
    "## note that we must first update the columns in restricted3 and restricted4 to match combined_df\n",
    "## we start with restricted3\n",
    "\n",
    "## note that we are currently using common_ids_sub_1 instead of common_ids\n",
    "\n",
    "col3_dict = {}\n",
    "\n",
    "for col in df3.columns:\n",
    "    if col != \"person_id\":\n",
    "        col3_dict[col] = col + \"_df3\"\n",
    "\n",
    "restricted3.rename(columns=col3_dict, inplace=True)\n",
    "\n",
    "restricted3.set_index(\"person_id\", inplace=True)\n",
    "\n",
    "for col in restricted3.columns:\n",
    "    if col != \"person_id\":\n",
    "        for pid in common_ids_sub_1:\n",
    "            combined_df.loc[pid][col] = restricted3.loc[pid][col]\n",
    "\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_df3</th>\n",
       "      <th>date_of_birth_df3</th>\n",
       "      <th>race_df3</th>\n",
       "      <th>ethnicity_df3</th>\n",
       "      <th>sex_at_birth_df3</th>\n",
       "      <th>observation_datetime_df4</th>\n",
       "      <th>zip_code_df4</th>\n",
       "      <th>assisted_income_df4</th>\n",
       "      <th>high_school_education_df4</th>\n",
       "      <th>median_income_df4</th>\n",
       "      <th>...</th>\n",
       "      <th>source_vocabulary_df2_48</th>\n",
       "      <th>condition_status_concept_name_df2_48</th>\n",
       "      <th>standard_concept_name_df2_49</th>\n",
       "      <th>condition_start_datetime_df2_49</th>\n",
       "      <th>condition_end_datetime_df2_49</th>\n",
       "      <th>condition_type_concept_name_df2_49</th>\n",
       "      <th>visit_occurrence_concept_name_df2_49</th>\n",
       "      <th>source_concept_name_df2_49</th>\n",
       "      <th>source_vocabulary_df2_49</th>\n",
       "      <th>condition_status_concept_name_df2_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000104</th>\n",
       "      <td>Female</td>\n",
       "      <td>1965-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-05-13 18:21:26+00:00</td>\n",
       "      <td>100**</td>\n",
       "      <td>17.355981</td>\n",
       "      <td>85.665558</td>\n",
       "      <td>83951.707638</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000109</th>\n",
       "      <td>Female</td>\n",
       "      <td>1967-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-06-19 20:17:10+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000131</th>\n",
       "      <td>Not man only, not woman only, prefer not to an...</td>\n",
       "      <td>2002-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2021-09-09 17:18:12+00:00</td>\n",
       "      <td>853**</td>\n",
       "      <td>13.019775</td>\n",
       "      <td>85.134547</td>\n",
       "      <td>61580.823283</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-04-15 19:33:14+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000291</th>\n",
       "      <td>Female</td>\n",
       "      <td>1962-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-07 16:09:49+00:00</td>\n",
       "      <td>100**</td>\n",
       "      <td>17.355981</td>\n",
       "      <td>85.665558</td>\n",
       "      <td>83951.707638</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000724</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2017-09-19 13:40:32+00:00</td>\n",
       "      <td>154**</td>\n",
       "      <td>20.910346</td>\n",
       "      <td>88.333925</td>\n",
       "      <td>42632.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001000</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-13 18:47:27+00:00</td>\n",
       "      <td>927**</td>\n",
       "      <td>15.58751</td>\n",
       "      <td>66.084673</td>\n",
       "      <td>69333.203649</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001034</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None of these</td>\n",
       "      <td>What Race Ethnicity: Race Ethnicity None Of These</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-05-17 18:48:39+00:00</td>\n",
       "      <td>850**</td>\n",
       "      <td>18.509215</td>\n",
       "      <td>78.387333</td>\n",
       "      <td>54223.044605</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001161</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2018-11-28 21:06:26+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001207</th>\n",
       "      <td>Female</td>\n",
       "      <td>1985-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-08-14 19:24:56+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gender_df3  \\\n",
       "person_id                                                      \n",
       "1000104                                               Female   \n",
       "1000109                                               Female   \n",
       "1000131    Not man only, not woman only, prefer not to an...   \n",
       "1000195                                               Female   \n",
       "1000291                                               Female   \n",
       "1000724                                               Female   \n",
       "1001000                                               Female   \n",
       "1001034                                               Female   \n",
       "1001161                                               Female   \n",
       "1001207                                               Female   \n",
       "\n",
       "                   date_of_birth_df3                   race_df3  \\\n",
       "person_id                                                         \n",
       "1000104    1965-06-15 00:00:00+00:00             None Indicated   \n",
       "1000109    1967-06-15 00:00:00+00:00             None Indicated   \n",
       "1000131    2002-06-15 00:00:00+00:00                      White   \n",
       "1000195    1982-06-15 00:00:00+00:00  Black or African American   \n",
       "1000291    1962-06-15 00:00:00+00:00             None Indicated   \n",
       "1000724    1999-06-15 00:00:00+00:00                      White   \n",
       "1001000    1999-06-15 00:00:00+00:00  Black or African American   \n",
       "1001034    1989-06-15 00:00:00+00:00              None of these   \n",
       "1001161    1989-06-15 00:00:00+00:00             None Indicated   \n",
       "1001207    1985-06-15 00:00:00+00:00             None Indicated   \n",
       "\n",
       "                                               ethnicity_df3 sex_at_birth_df3  \\\n",
       "person_id                                                                       \n",
       "1000104                                   Hispanic or Latino           Female   \n",
       "1000109                                   Hispanic or Latino           Female   \n",
       "1000131                               Not Hispanic or Latino           Female   \n",
       "1000195                               Not Hispanic or Latino           Female   \n",
       "1000291                                   Hispanic or Latino           Female   \n",
       "1000724                               Not Hispanic or Latino           Female   \n",
       "1001000                                   Hispanic or Latino           Female   \n",
       "1001034    What Race Ethnicity: Race Ethnicity None Of These           Female   \n",
       "1001161                                   Hispanic or Latino           Female   \n",
       "1001207                                   Hispanic or Latino           Female   \n",
       "\n",
       "            observation_datetime_df4 zip_code_df4 assisted_income_df4  \\\n",
       "person_id                                                               \n",
       "1000104    2019-05-13 18:21:26+00:00        100**           17.355981   \n",
       "1000109    2019-06-19 20:17:10+00:00        104**           38.279736   \n",
       "1000131    2021-09-09 17:18:12+00:00        853**           13.019775   \n",
       "1000195    2019-04-15 19:33:14+00:00        104**           38.279736   \n",
       "1000291    2020-02-07 16:09:49+00:00        100**           17.355981   \n",
       "1000724    2017-09-19 13:40:32+00:00        154**           20.910346   \n",
       "1001000    2020-02-13 18:47:27+00:00        927**            15.58751   \n",
       "1001034    2019-05-17 18:48:39+00:00        850**           18.509215   \n",
       "1001161    2018-11-28 21:06:26+00:00        104**           38.279736   \n",
       "1001207    2019-08-14 19:24:56+00:00        104**           38.279736   \n",
       "\n",
       "          high_school_education_df4 median_income_df4  ...  \\\n",
       "person_id                                              ...   \n",
       "1000104                   85.665558      83951.707638  ...   \n",
       "1000109                   70.896923      39407.415829  ...   \n",
       "1000131                   85.134547      61580.823283  ...   \n",
       "1000195                   70.896923      39407.415829  ...   \n",
       "1000291                   85.665558      83951.707638  ...   \n",
       "1000724                   88.333925      42632.000716  ...   \n",
       "1001000                   66.084673      69333.203649  ...   \n",
       "1001034                   78.387333      54223.044605  ...   \n",
       "1001161                   70.896923      39407.415829  ...   \n",
       "1001207                   70.896923      39407.415829  ...   \n",
       "\n",
       "          source_vocabulary_df2_48 condition_status_concept_name_df2_48  \\\n",
       "person_id                                                                 \n",
       "1000104                       temp                                 temp   \n",
       "1000109                       temp                                 temp   \n",
       "1000131                       temp                                 temp   \n",
       "1000195                       temp                                 temp   \n",
       "1000291                       temp                                 temp   \n",
       "1000724                       temp                                 temp   \n",
       "1001000                       temp                                 temp   \n",
       "1001034                       temp                                 temp   \n",
       "1001161                       temp                                 temp   \n",
       "1001207                       temp                                 temp   \n",
       "\n",
       "          standard_concept_name_df2_49 condition_start_datetime_df2_49  \\\n",
       "person_id                                                                \n",
       "1000104                           temp                            temp   \n",
       "1000109                           temp                            temp   \n",
       "1000131                           temp                            temp   \n",
       "1000195                           temp                            temp   \n",
       "1000291                           temp                            temp   \n",
       "1000724                           temp                            temp   \n",
       "1001000                           temp                            temp   \n",
       "1001034                           temp                            temp   \n",
       "1001161                           temp                            temp   \n",
       "1001207                           temp                            temp   \n",
       "\n",
       "          condition_end_datetime_df2_49 condition_type_concept_name_df2_49  \\\n",
       "person_id                                                                    \n",
       "1000104                            temp                               temp   \n",
       "1000109                            temp                               temp   \n",
       "1000131                            temp                               temp   \n",
       "1000195                            temp                               temp   \n",
       "1000291                            temp                               temp   \n",
       "1000724                            temp                               temp   \n",
       "1001000                            temp                               temp   \n",
       "1001034                            temp                               temp   \n",
       "1001161                            temp                               temp   \n",
       "1001207                            temp                               temp   \n",
       "\n",
       "          visit_occurrence_concept_name_df2_49 source_concept_name_df2_49  \\\n",
       "person_id                                                                   \n",
       "1000104                                   temp                       temp   \n",
       "1000109                                   temp                       temp   \n",
       "1000131                                   temp                       temp   \n",
       "1000195                                   temp                       temp   \n",
       "1000291                                   temp                       temp   \n",
       "1000724                                   temp                       temp   \n",
       "1001000                                   temp                       temp   \n",
       "1001034                                   temp                       temp   \n",
       "1001161                                   temp                       temp   \n",
       "1001207                                   temp                       temp   \n",
       "\n",
       "          source_vocabulary_df2_49 condition_status_concept_name_df2_49  \n",
       "person_id                                                                \n",
       "1000104                       temp                                 temp  \n",
       "1000109                       temp                                 temp  \n",
       "1000131                       temp                                 temp  \n",
       "1000195                       temp                                 temp  \n",
       "1000291                       temp                                 temp  \n",
       "1000724                       temp                                 temp  \n",
       "1001000                       temp                                 temp  \n",
       "1001034                       temp                                 temp  \n",
       "1001161                       temp                                 temp  \n",
       "1001207                       temp                                 temp  \n",
       "\n",
       "[10 rows x 407 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now we do the same thing with restricted4\n",
    "\n",
    "## note that we are currently using common_ids_sub_1 instead of common_ids\n",
    "\n",
    "col4_dict = {}\n",
    "\n",
    "for col in df4.columns:\n",
    "    if col != \"person_id\":\n",
    "        col4_dict[col] = col + \"_df4\"\n",
    "\n",
    "restricted4.rename(columns=col4_dict, inplace=True)\n",
    "\n",
    "restricted4.set_index(\"person_id\", inplace=True)\n",
    "\n",
    "for col in restricted4.columns:\n",
    "    if col != \"person_id\":\n",
    "        for pid in common_ids_sub_1:\n",
    "            combined_df.loc[pid][col] = restricted4.loc[pid][col]\n",
    "\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently skipping this cell, switching it to markdown for now\n",
    "\n",
    "##### we now handle the cases of restricted1\n",
    "##### for a fixed pair of values (pid,col) of person_id and a column from restricted1, \n",
    "##### we can create a new data frame - mini_df - with the correct number of columns and correct column names\n",
    "##### we can then update the entries in combined_df accordingly\n",
    "\n",
    "col1 = []\n",
    "\n",
    "for col in df1.columns:\n",
    "    if col != \"person_id\":\n",
    "        col1.append(col)\n",
    "\n",
    "##### recall dict1_mult is the maximal multiplicity of a person_id value in restricted1\n",
    "\n",
    "##### note that we are currently using common_ids_sub_1 instead of common_ids\n",
    "\n",
    "max = dict1_mult\n",
    "\n",
    "##### some columns are weird and the .tolist() method does not work\n",
    "##### question_concept_id, answer_concept_id, survey_version_id throw problems and aren't helpful,\n",
    "##### so I'm going to drop them at the beginning\n",
    "\n",
    "      \n",
    "for pid in common_ids_sub_1:\n",
    "    for col in col1:\n",
    "        col_values = restricted1[restricted1[\"person_id\"] == pid][col].values.tolist()\n",
    "        mini_df_cols = []\n",
    "        for index in range(1,max+1):\n",
    "            mini_df_cols.append(col+\"_df1_\"+str(index))\n",
    "        mini_df_dict = {}\n",
    "        for index in range(0,len(col_values)):\n",
    "            mini_df_dict[mini_df_cols[index]] = [col_values[index]]\n",
    "        for index in range(len(col_values),max):\n",
    "            mini_df_dict[mini_df_cols[index]] = [\"N/A\"]\n",
    "        mini_df = pd.DataFrame(mini_df_dict)\n",
    "        for newcol in mini_df_cols:\n",
    "            combined_df.loc[pid][newcol] = mini_df.loc[0][newcol]\n",
    "\n",
    "        \n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_df3</th>\n",
       "      <th>date_of_birth_df3</th>\n",
       "      <th>race_df3</th>\n",
       "      <th>ethnicity_df3</th>\n",
       "      <th>sex_at_birth_df3</th>\n",
       "      <th>observation_datetime_df4</th>\n",
       "      <th>zip_code_df4</th>\n",
       "      <th>assisted_income_df4</th>\n",
       "      <th>high_school_education_df4</th>\n",
       "      <th>median_income_df4</th>\n",
       "      <th>...</th>\n",
       "      <th>source_vocabulary_df2_48</th>\n",
       "      <th>condition_status_concept_name_df2_48</th>\n",
       "      <th>standard_concept_name_df2_49</th>\n",
       "      <th>condition_start_datetime_df2_49</th>\n",
       "      <th>condition_end_datetime_df2_49</th>\n",
       "      <th>condition_type_concept_name_df2_49</th>\n",
       "      <th>visit_occurrence_concept_name_df2_49</th>\n",
       "      <th>source_concept_name_df2_49</th>\n",
       "      <th>source_vocabulary_df2_49</th>\n",
       "      <th>condition_status_concept_name_df2_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000104</th>\n",
       "      <td>Female</td>\n",
       "      <td>1965-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-05-13 18:21:26+00:00</td>\n",
       "      <td>100**</td>\n",
       "      <td>17.355981</td>\n",
       "      <td>85.665558</td>\n",
       "      <td>83951.707638</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000109</th>\n",
       "      <td>Female</td>\n",
       "      <td>1967-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-06-19 20:17:10+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000131</th>\n",
       "      <td>Not man only, not woman only, prefer not to an...</td>\n",
       "      <td>2002-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2021-09-09 17:18:12+00:00</td>\n",
       "      <td>853**</td>\n",
       "      <td>13.019775</td>\n",
       "      <td>85.134547</td>\n",
       "      <td>61580.823283</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-04-15 19:33:14+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000291</th>\n",
       "      <td>Female</td>\n",
       "      <td>1962-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-07 16:09:49+00:00</td>\n",
       "      <td>100**</td>\n",
       "      <td>17.355981</td>\n",
       "      <td>85.665558</td>\n",
       "      <td>83951.707638</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000724</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2017-09-19 13:40:32+00:00</td>\n",
       "      <td>154**</td>\n",
       "      <td>20.910346</td>\n",
       "      <td>88.333925</td>\n",
       "      <td>42632.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001000</th>\n",
       "      <td>Female</td>\n",
       "      <td>1999-06-15 00:00:00+00:00</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-13 18:47:27+00:00</td>\n",
       "      <td>927**</td>\n",
       "      <td>15.58751</td>\n",
       "      <td>66.084673</td>\n",
       "      <td>69333.203649</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001034</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None of these</td>\n",
       "      <td>What Race Ethnicity: Race Ethnicity None Of These</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-05-17 18:48:39+00:00</td>\n",
       "      <td>850**</td>\n",
       "      <td>18.509215</td>\n",
       "      <td>78.387333</td>\n",
       "      <td>54223.044605</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001161</th>\n",
       "      <td>Female</td>\n",
       "      <td>1989-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2018-11-28 21:06:26+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001207</th>\n",
       "      <td>Female</td>\n",
       "      <td>1985-06-15 00:00:00+00:00</td>\n",
       "      <td>None Indicated</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-08-14 19:24:56+00:00</td>\n",
       "      <td>104**</td>\n",
       "      <td>38.279736</td>\n",
       "      <td>70.896923</td>\n",
       "      <td>39407.415829</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gender_df3  \\\n",
       "person_id                                                      \n",
       "1000104                                               Female   \n",
       "1000109                                               Female   \n",
       "1000131    Not man only, not woman only, prefer not to an...   \n",
       "1000195                                               Female   \n",
       "1000291                                               Female   \n",
       "1000724                                               Female   \n",
       "1001000                                               Female   \n",
       "1001034                                               Female   \n",
       "1001161                                               Female   \n",
       "1001207                                               Female   \n",
       "\n",
       "                   date_of_birth_df3                   race_df3  \\\n",
       "person_id                                                         \n",
       "1000104    1965-06-15 00:00:00+00:00             None Indicated   \n",
       "1000109    1967-06-15 00:00:00+00:00             None Indicated   \n",
       "1000131    2002-06-15 00:00:00+00:00                      White   \n",
       "1000195    1982-06-15 00:00:00+00:00  Black or African American   \n",
       "1000291    1962-06-15 00:00:00+00:00             None Indicated   \n",
       "1000724    1999-06-15 00:00:00+00:00                      White   \n",
       "1001000    1999-06-15 00:00:00+00:00  Black or African American   \n",
       "1001034    1989-06-15 00:00:00+00:00              None of these   \n",
       "1001161    1989-06-15 00:00:00+00:00             None Indicated   \n",
       "1001207    1985-06-15 00:00:00+00:00             None Indicated   \n",
       "\n",
       "                                               ethnicity_df3 sex_at_birth_df3  \\\n",
       "person_id                                                                       \n",
       "1000104                                   Hispanic or Latino           Female   \n",
       "1000109                                   Hispanic or Latino           Female   \n",
       "1000131                               Not Hispanic or Latino           Female   \n",
       "1000195                               Not Hispanic or Latino           Female   \n",
       "1000291                                   Hispanic or Latino           Female   \n",
       "1000724                               Not Hispanic or Latino           Female   \n",
       "1001000                                   Hispanic or Latino           Female   \n",
       "1001034    What Race Ethnicity: Race Ethnicity None Of These           Female   \n",
       "1001161                                   Hispanic or Latino           Female   \n",
       "1001207                                   Hispanic or Latino           Female   \n",
       "\n",
       "            observation_datetime_df4 zip_code_df4 assisted_income_df4  \\\n",
       "person_id                                                               \n",
       "1000104    2019-05-13 18:21:26+00:00        100**           17.355981   \n",
       "1000109    2019-06-19 20:17:10+00:00        104**           38.279736   \n",
       "1000131    2021-09-09 17:18:12+00:00        853**           13.019775   \n",
       "1000195    2019-04-15 19:33:14+00:00        104**           38.279736   \n",
       "1000291    2020-02-07 16:09:49+00:00        100**           17.355981   \n",
       "1000724    2017-09-19 13:40:32+00:00        154**           20.910346   \n",
       "1001000    2020-02-13 18:47:27+00:00        927**            15.58751   \n",
       "1001034    2019-05-17 18:48:39+00:00        850**           18.509215   \n",
       "1001161    2018-11-28 21:06:26+00:00        104**           38.279736   \n",
       "1001207    2019-08-14 19:24:56+00:00        104**           38.279736   \n",
       "\n",
       "          high_school_education_df4 median_income_df4  ...  \\\n",
       "person_id                                              ...   \n",
       "1000104                   85.665558      83951.707638  ...   \n",
       "1000109                   70.896923      39407.415829  ...   \n",
       "1000131                   85.134547      61580.823283  ...   \n",
       "1000195                   70.896923      39407.415829  ...   \n",
       "1000291                   85.665558      83951.707638  ...   \n",
       "1000724                   88.333925      42632.000716  ...   \n",
       "1001000                   66.084673      69333.203649  ...   \n",
       "1001034                   78.387333      54223.044605  ...   \n",
       "1001161                   70.896923      39407.415829  ...   \n",
       "1001207                   70.896923      39407.415829  ...   \n",
       "\n",
       "          source_vocabulary_df2_48 condition_status_concept_name_df2_48  \\\n",
       "person_id                                                                 \n",
       "1000104                        N/A                                  N/A   \n",
       "1000109                        N/A                                  N/A   \n",
       "1000131                        N/A                                  N/A   \n",
       "1000195                        N/A                                  N/A   \n",
       "1000291                        N/A                                  N/A   \n",
       "1000724                        N/A                                  N/A   \n",
       "1001000                        N/A                                  N/A   \n",
       "1001034                        N/A                                  N/A   \n",
       "1001161                        N/A                                  N/A   \n",
       "1001207                        N/A                                  N/A   \n",
       "\n",
       "          standard_concept_name_df2_49 condition_start_datetime_df2_49  \\\n",
       "person_id                                                                \n",
       "1000104                            N/A                             N/A   \n",
       "1000109                            N/A                             N/A   \n",
       "1000131                            N/A                             N/A   \n",
       "1000195                            N/A                             N/A   \n",
       "1000291                            N/A                             N/A   \n",
       "1000724                            N/A                             N/A   \n",
       "1001000                            N/A                             N/A   \n",
       "1001034                            N/A                             N/A   \n",
       "1001161                            N/A                             N/A   \n",
       "1001207                            N/A                             N/A   \n",
       "\n",
       "          condition_end_datetime_df2_49 condition_type_concept_name_df2_49  \\\n",
       "person_id                                                                    \n",
       "1000104                             N/A                                N/A   \n",
       "1000109                             N/A                                N/A   \n",
       "1000131                             N/A                                N/A   \n",
       "1000195                             N/A                                N/A   \n",
       "1000291                             N/A                                N/A   \n",
       "1000724                             N/A                                N/A   \n",
       "1001000                             N/A                                N/A   \n",
       "1001034                             N/A                                N/A   \n",
       "1001161                             N/A                                N/A   \n",
       "1001207                             N/A                                N/A   \n",
       "\n",
       "          visit_occurrence_concept_name_df2_49 source_concept_name_df2_49  \\\n",
       "person_id                                                                   \n",
       "1000104                                    N/A                        N/A   \n",
       "1000109                                    N/A                        N/A   \n",
       "1000131                                    N/A                        N/A   \n",
       "1000195                                    N/A                        N/A   \n",
       "1000291                                    N/A                        N/A   \n",
       "1000724                                    N/A                        N/A   \n",
       "1001000                                    N/A                        N/A   \n",
       "1001034                                    N/A                        N/A   \n",
       "1001161                                    N/A                        N/A   \n",
       "1001207                                    N/A                        N/A   \n",
       "\n",
       "          source_vocabulary_df2_49 condition_status_concept_name_df2_49  \n",
       "person_id                                                                \n",
       "1000104                        N/A                                  N/A  \n",
       "1000109                        N/A                                  N/A  \n",
       "1000131                        N/A                                  N/A  \n",
       "1000195                        N/A                                  N/A  \n",
       "1000291                        N/A                                  N/A  \n",
       "1000724                        N/A                                  N/A  \n",
       "1001000                        N/A                                  N/A  \n",
       "1001034                        N/A                                  N/A  \n",
       "1001161                        N/A                                  N/A  \n",
       "1001207                        N/A                                  N/A  \n",
       "\n",
       "[10 rows x 407 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we now repeat what we did for restricted1 for restricted 2\n",
    "\n",
    "col2 = []\n",
    "\n",
    "for col in df2.columns:\n",
    "    if col != \"person_id\":\n",
    "        col2.append(col)\n",
    "\n",
    "## recall dict2_mult is the maximal multiplicity of a person_id value in restricted1\n",
    "\n",
    "max = dict2_mult\n",
    "\n",
    "## note that we are currently using common_ids_sub_1 instead of common_ids\n",
    "\n",
    "# some columns are weird and the .tolist() method does not work\n",
    "# condition_concept_id', 'condition_type_concept_id', 'visit_occurrence_id', \n",
    "# 'condition_source_concept_id', 'condition_status_concept_id' throw problems\n",
    "# and aren't helpful, so I'm going to drop them at the beginning\n",
    "        \n",
    "for pid in common_ids_sub_1:\n",
    "    for col in col2:\n",
    "        col_values = restricted2[restricted2[\"person_id\"] == pid][col].values.tolist()\n",
    "        mini_df_cols = []\n",
    "        for index in range(1,max+1):\n",
    "            mini_df_cols.append(col+\"_df2_\"+str(index))\n",
    "        mini_df_dict = {}\n",
    "        for index in range(0,len(col_values)):\n",
    "            mini_df_dict[mini_df_cols[index]] = [col_values[index]]\n",
    "        for index in range(len(col_values),max):\n",
    "            mini_df_dict[mini_df_cols[index]] = [\"N/A\"]\n",
    "        mini_df = pd.DataFrame(mini_df_dict)\n",
    "        for newcol in mini_df_cols:\n",
    "            combined_df.loc[pid][newcol] = mini_df.loc[0][newcol]\n",
    "\n",
    "                \n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cells below are from previous work. Maintaining for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check what is the index of each data frame... Df_names based on concept sets from All of Us. \n",
    "dataframes = [df1, df2, df3, df4]\n",
    "df_names = ['survey_df', 'condition_df', 'person_df', 'zipcode_df']\n",
    "\n",
    "for df_names, dataframe in zip(df_names, dataframes):\n",
    "    print(f\"{df_names}: Index column: {dataframe.index.name}\")\n",
    "\n",
    "#zip puts together the names of the dataframes and the list of dataframes\n",
    "#so that the loop returns the names of the dataframe       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df1.columns) code used to check for all column names in dataframe    \n",
    "\n",
    "#Set index for each dataframe to \"person_id\" or print that person_id is not found in any column of the dataframe.\n",
    "dataframes = [df1, df2, df3, df4]\n",
    "df_names = ['survey_df', 'condition_df', 'person_df', 'zipcode_df']\n",
    "\n",
    "for df_names, dataframe in zip (df_names, dataframes):\n",
    "    if dataframe.index.name == 'person_id':\n",
    "        print(f\" {df_names} index is person_id\")\n",
    "              \n",
    "    elif 'person_id' in dataframe.columns:\n",
    "        dataframe.set_index('person_id', inplace=True)\n",
    "        print(f\"'person_id' is now the index for {df_names}\")\n",
    "              \n",
    "    else: \n",
    "        print (f\" person_id not found in {df_names}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check for duplicate person_id, indicative of multiple rows per person_id. Duplicates will need to be \n",
    "#resolved before dataframes can be merged together.\n",
    "\n",
    "dataframes = [df1, df2, df3, df4]\n",
    "df_names = ['survey_df', 'condition_df', 'person_df', 'zipcode_df']\n",
    "\n",
    "for df_names, dataframe in zip(df_names, dataframes):\n",
    "    duplicates = dataframe.index[dataframe.index.duplicated(keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        print(f\" {df_names} has duplicate 'person_id' values in the index:\")\n",
    "        print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 (survey) and df4 (zipcode) do not have multiple rows per index (person_id) so they can be joined right away\n",
    "\n",
    "\n",
    "join_df = df3.join(df4, how='inner')\n",
    "\n",
    "#Resets the index to a regular column and keeps person_id as a column\n",
    "join_df.reset_index(inplace=True)\n",
    "\n",
    "#Rename columns if they have the same name in both dataframes:\n",
    "join_df = join_df.add_suffix('_df4')\n",
    "\n",
    "join_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to clean up the multiple rows per person... Here is an example of what multiple rows for one person looks like.\n",
    "#This individual had three births, represented by 5 lines. We need to decide how to treat this. For example, changing the\n",
    "#person id to be 2920867a, 2920867b, 2920867c. Also probably need to drop \"single live birth\" when \"preterm birth\" is \n",
    "#present for the same date (key is knowing how the data is recorded), and \"single live birth\" and \"outcome of delivery:\n",
    "#single liveborn\" is also a duplicate, so we would probably drop the latter condition label... \n",
    " \n",
    "person_id = 2920867\n",
    "\n",
    "# Filter the DataFrame to get all rows for the specific person_id using .loc\n",
    "person_data = df2.loc[df2.index == person_id]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(person_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is my outline for approaching this:\n",
    "#   1) Create dictionaries for df1, df2, df3, df4 which note the values of person_id and their multiplicities\n",
    "#   2) Create a list of values of person_id which occur in all four data frames\n",
    "#   3) Construct a new data frame (in stages) from the list created in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each dataframe needs to be reshaped individually in order to put multiple person_id rows into one row per person. Note that \n",
    "#because we do not want to aggregate or sum data, that this will result in new columns and duplicate columns will be renamed\n",
    "#e.g. survey, survey_2, and so on.\n",
    "\n",
    "#Only condition and survey have duplicate rows\n",
    "\n",
    "#Each dataframe needs to be reshaped individually in order to put multiple person_id rows into one row per person, \n",
    "#before they are merged into one super dataframe. Don't make this a loop or you will die waiting. \n",
    "\n",
    "#I think we need to reduce rows first because this code takes forever to run and I'm not even sure it works\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataframes = [df1, df2]\n",
    "df_names = [\"survey_df\", \"condition_df\"]\n",
    "\n",
    "# Create an empty DataFrame to store the reshaped data\n",
    "reshaped_df1 = pd.DataFrame()\n",
    "\n",
    "# Iterate through each 'person_id' in the index\n",
    "for person_id in df1.index.unique():\n",
    "    # Extract the data for the specific 'person_id'\n",
    "    person_data = df1.loc[person_id]\n",
    "\n",
    "    # Reset the index to get a unique integer index, but keep 'person_id' data as a new column\n",
    "    person_data = person_data.reset_index(drop=False)\n",
    "\n",
    "    # Rename the columns for this person with suffix _X\n",
    "    person_data.columns = [f\"{col}_{i}\" for i, col in enumerate(person_data.columns)]\n",
    "\n",
    "    # Add the person's data as a row in the reshaped DataFrame\n",
    "    reshaped_df1 = pd.concat([reshaped_df1, person_data], axis=1)\n",
    "\n",
    "# Transpose the reshaped DataFrame to have 'person_id' as the index\n",
    "reshaped_df1 = reshaped_df1.T\n",
    "\n",
    "# Reset the index so that 'person_id' becomes a regular column\n",
    "reshaped_df1.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match your requirements\n",
    "reshaped_df1.columns = ['person_id'] + reshaped_df1.columns[1:]\n",
    "\n",
    "# Optional: Reset the index to have continuous integers\n",
    "# reshaped_df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the reshaped DataFrame\n",
    "reshaped_df1.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the reshaped data\n",
    "reshaped_df2 = pd.DataFrame()\n",
    "\n",
    "# Iterate through each 'person_id' in the index\n",
    "for person_id in df2.index.unique():\n",
    "    # Extract the data for the specific 'person_id'\n",
    "    person_data = df2.loc[person_id]\n",
    "\n",
    "    # Reset the index to get a unique integer index, but keep 'person_id' data as a new column\n",
    "    person_data = person_data.reset_index(drop=False)\n",
    "\n",
    "    # Rename the columns for this person with suffix _X\n",
    "    person_data.columns = [f\"{col}_{i}\" for i, col in enumerate(person_data.columns)]\n",
    "\n",
    "    # Add the person's data as a row in the reshaped DataFrame\n",
    "    reshaped_df2 = pd.concat([reshaped_df2, person_data], axis=1)\n",
    "\n",
    "# Transpose the reshaped DataFrame to have 'person_id' as the index\n",
    "reshaped_df2 = reshaped_df2.T\n",
    "\n",
    "# Reset the index so that 'person_id' becomes a regular column\n",
    "reshaped_df2.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match your requirements\n",
    "reshaped_df2.columns = ['person_id'] + reshaped_df2.columns[1:]\n",
    "\n",
    "# Optional: Reset the index to have continuous integers\n",
    "# reshaped_df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the reshaped DataFrame\n",
    "reshaped_df2.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_96162923_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                JOIN\n",
    "                    (\n",
    "                        select\n",
    "                            cast(cr.id as string) as id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                        WHERE\n",
    "                            concept_id IN (\n",
    "                                1586134,43528895,40192389\n",
    "                            ) \n",
    "                            AND domain_id = 'SURVEY'\n",
    "                    ) a \n",
    "                        ON (\n",
    "                            c.path like CONCAT('%',\n",
    "                        a.id,\n",
    "                        '.%')) \n",
    "                    WHERE\n",
    "                        domain_id = 'SURVEY' \n",
    "                        AND type = 'PPI' \n",
    "                        AND subtype = 'QUESTION'\n",
    "                    )\n",
    "            )  \n",
    "            AND (\n",
    "                answer.PERSON_ID IN (\n",
    "                    SELECT\n",
    "                        distinct person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                    WHERE\n",
    "                        cb_search_person.person_id IN (\n",
    "                            SELECT\n",
    "                                criteria.person_id \n",
    "                            FROM\n",
    "                                (SELECT\n",
    "                                    DISTINCT person_id,\n",
    "                                    entry_date,\n",
    "                                    concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                WHERE\n",
    "                                    (\n",
    "                                        concept_id IN (\n",
    "                                            SELECT\n",
    "                                                DISTINCT c.concept_id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                            JOIN\n",
    "                                                (\n",
    "                                                    select\n",
    "                                                        cast(cr.id as string) as id \n",
    "                                                    FROM\n",
    "                                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                    WHERE\n",
    "                                                        concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                        AND full_text LIKE '%_rank1]%'\n",
    "                                                ) a \n",
    "                                                    ON (\n",
    "                                                        c.path LIKE CONCAT('%.',\n",
    "                                                    a.id,\n",
    "                                                    '.%') \n",
    "                                                    OR c.path LIKE CONCAT('%.',\n",
    "                                                    a.id) \n",
    "                                                    OR c.path LIKE CONCAT(a.id,\n",
    "                                                    '.%') \n",
    "                                                    OR c.path = a.id) \n",
    "                                                WHERE\n",
    "                                                    is_standard = 1 \n",
    "                                                    AND is_selectable = 1\n",
    "                                                ) \n",
    "                                                AND is_standard = 1 \n",
    "                                        )\n",
    "                                    ) criteria \n",
    "                                ) ))\"\"\"\n",
    "\n",
    "dataset_96162923_survey_df = pandas.read_gbq(\n",
    "    dataset_96162923_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_96162923_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_96162923_condition_sql = \"\"\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_occurrence.condition_type_concept_id,\n",
    "        c_type.concept_name as condition_type_concept_name,\n",
    "        c_occurrence.stop_reason,\n",
    "        c_occurrence.visit_occurrence_id,\n",
    "        visit.concept_name as visit_occurrence_concept_name,\n",
    "        c_occurrence.condition_source_value,\n",
    "        c_occurrence.condition_source_concept_id,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code,\n",
    "        c_source_concept.vocabulary_id as source_vocabulary,\n",
    "        c_occurrence.condition_status_source_value,\n",
    "        c_occurrence.condition_status_concept_id,\n",
    "        c_status.concept_name as condition_status_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN  (\n",
    "                    SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (\n",
    "                            select\n",
    "                                cast(cr.id as string) as id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                            WHERE\n",
    "                                concept_id IN (\n",
    "                                    36712702, 4014295, 4040733, 4127852, 4129479, 4217564, 4282746, 432441, 43531419, 436740, 441077, 44784550, 45757175, 45757176\n",
    "                                ) \n",
    "                                AND full_text LIKE '%_rank1]%'\n",
    "                        ) a \n",
    "                            ON (\n",
    "                                c.path LIKE CONCAT('%.',\n",
    "                            a.id,\n",
    "                            '.%') \n",
    "                            OR c.path LIKE CONCAT('%.',\n",
    "                            a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id,\n",
    "                            '.%') \n",
    "                            OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1\n",
    "                        )\n",
    "                )  \n",
    "                AND (\n",
    "                    c_occurrence.PERSON_ID IN (\n",
    "                        SELECT\n",
    "                            distinct person_id  \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                        WHERE\n",
    "                            cb_search_person.person_id IN (\n",
    "                                SELECT\n",
    "                                    criteria.person_id \n",
    "                                FROM\n",
    "                                    (SELECT\n",
    "                                        DISTINCT person_id,\n",
    "                                        entry_date,\n",
    "                                        concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                    WHERE\n",
    "                                        (\n",
    "                                            concept_id IN (\n",
    "                                                SELECT\n",
    "                                                    DISTINCT c.concept_id \n",
    "                                                FROM\n",
    "                                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                                JOIN\n",
    "                                                    (\n",
    "                                                        select\n",
    "                                                            cast(cr.id as string) as id \n",
    "                                                        FROM\n",
    "                                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                        WHERE\n",
    "                                                            concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                            AND full_text LIKE '%_rank1]%'\n",
    "                                                    ) a \n",
    "                                                        ON (\n",
    "                                                            c.path LIKE CONCAT('%.',\n",
    "                                                        a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path LIKE CONCAT('%.',\n",
    "                                                        a.id) \n",
    "                                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path = a.id) \n",
    "                                                    WHERE\n",
    "                                                        is_standard = 1 \n",
    "                                                        AND is_selectable = 1\n",
    "                                                    ) \n",
    "                                                    AND is_standard = 1 \n",
    "                                            )\n",
    "                                        ) criteria \n",
    "                                    ) ))\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "dataset_96162923_condition_df = pandas.read_gbq(\n",
    "    dataset_96162923_condition_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_96162923_condition_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_96162923_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) )  \n",
    "                    AND (person.PERSON_ID IN (SELECT\n",
    "                        DISTINCT person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` \n",
    "                    WHERE\n",
    "                        has_ehr_data = 1))\"\"\"\n",
    "\n",
    "dataset_96162923_person_df = pandas.read_gbq(\n",
    "    dataset_96162923_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_96162923_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"AS_KG_Dataset\" for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_96162923_zip_code_socioeconomic_sql = \"\"\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".zip3_ses_map` zip_code \n",
    "    JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string,\n",
    "        0,\n",
    "        STRPOS(observation.value_as_string,\n",
    "        '*') - 1) AS INT64) = zip_code.zip3  \n",
    "    WHERE\n",
    "        observation.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (36712702, 45757176, 4014295) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) ) \n",
    "                    AND observation_source_concept_id = 1585250 \n",
    "                    AND observation.value_as_string NOT LIKE 'Res%'\"\"\"\n",
    "\n",
    "dataset_96162923_zip_code_socioeconomic_df = pandas.read_gbq(\n",
    "    dataset_96162923_zip_code_socioeconomic_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_96162923_zip_code_socioeconomic_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
